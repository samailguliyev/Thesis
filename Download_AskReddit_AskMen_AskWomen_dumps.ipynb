{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## askreddit download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pySmartDL import SmartDL\n",
    "import os\n",
    "\n",
    "url = 'https://the-eye.eu/redarcs/files/AskReddit_comments.zst'\n",
    "dest = \"/pfs/work7/workspace/scratch/ma_sguliyev-Reddit_dumps/AskReddit_download/AskReddit_comments.zst\"  # choose your own destination\n",
    "\n",
    "dl = SmartDL(url, dest)\n",
    "dl.start()\n",
    "\n",
    "while not dl.isFinished():\n",
    "    print(\"Speed: %s\" % dl.get_speed(human=True))\n",
    "    print(\"Already downloaded: %s\" % dl.get_downloaded_bytes(human=True))\n",
    "    print(\"ETA: %s\" % dl.get_eta(human=True))\n",
    "    print(\"\\n\")  # print a newline character\n",
    "\n",
    "print(\"Download finished. File saved to %s\" % dl.get_dest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### askmen download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pySmartDL import SmartDL\n",
    "import os\n",
    "\n",
    "url = 'https://the-eye.eu/redarcs/files/AskMen_comments.zst'\n",
    "dest = \"/pfs/work7/workspace/scratch/ma_sguliyev-Reddit_dumps/AskMen_download/AskMen_comments.zst\"  # choose your own destination\n",
    "\n",
    "dl = SmartDL(url, dest)\n",
    "dl.start()\n",
    "\n",
    "while not dl.isFinished():\n",
    "    print(\"Speed: %s\" % dl.get_speed(human=True))\n",
    "    print(\"Already downloaded: %s\" % dl.get_downloaded_bytes(human=True))\n",
    "    print(\"ETA: %s\" % dl.get_eta(human=True))\n",
    "    print(\"\\n\")  # print a newline character\n",
    "\n",
    "print(\"Download finished. File saved to %s\" % dl.get_dest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### askwomen download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pySmartDL import SmartDL\n",
    "import os\n",
    "\n",
    "url = 'https://the-eye.eu/redarcs/files/AskWomen_comments.zst'\n",
    "dest = \"/pfs/work7/workspace/scratch/ma_sguliyev-Reddit_dumps/AskWomen_download/AskWomen_comments.zst\"  # choose your own destination\n",
    "\n",
    "dl = SmartDL(url, dest)\n",
    "dl.start()\n",
    "\n",
    "while not dl.isFinished():\n",
    "    print(\"Speed: %s\" % dl.get_speed(human=True))\n",
    "    print(\"Already downloaded: %s\" % dl.get_downloaded_bytes(human=True))\n",
    "    print(\"ETA: %s\" % dl.get_eta(human=True))\n",
    "    print(\"\\n\")  # print a newline character\n",
    "\n",
    "print(\"Download finished. File saved to %s\" % dl.get_dest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After you downloaded dumps unzip them\n",
    "## Code below then splits them into chunks for further processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_file(file_name, output_folder = False ,  chunks_count = 1000 ):\n",
    "    total_size = os.path.getsize(file_name)  # total file size in bytes\n",
    "    chunk_size = total_size // chunks_count  # size of each chunk\n",
    "    read_size = 0  # total size read so far\n",
    "    chunk_index = 1  # current chunk index\n",
    "    \n",
    "\n",
    "    with open(file_name, 'r') as f:\n",
    "        while read_size < total_size:\n",
    "            # open a new chunk file in write mode\n",
    "            if output_folder:\n",
    "                out_filename = f'{output_folder}/AskReddit_comments_chunk_{chunk_index}'\n",
    "            else:\n",
    "                out_filename = f'{file_name}_chunk_{chunk_index}'\n",
    "\n",
    "            with open(out_filename, 'w') as chunk_file:\n",
    "\n",
    "                while read_size < chunk_size * chunk_index:\n",
    "                    line = f.readline()\n",
    "                    read_size += len(line)\n",
    "                    chunk_file.write(line)\n",
    "                chunk_index += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage Below\n",
    "## Code continues to run forever after splitting into all chunks, need to stop manually (need to fix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function\n",
    "split_file(\n",
    "    '/pfs/work7/workspace/scratch/ma_sguliyev-Reddit_dumps/AskReddit_download/AskReddit_comments',\n",
    "    \"/pfs/work7/workspace/scratch/ma_sguliyev-Reddit_dumps/AskReddit_download/AskReddit_chunks\",\n",
    "    1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
